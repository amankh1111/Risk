{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "import scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data\n",
    "## Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('demo_data/DemoTgt.csv', sep = ',', decimal = '.', encoding = 'utf-8',\n",
    "                   low_memory=False, keep_default_na=False, na_values = [''])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define column with time\n",
    "If we want to use only certain time period for the target analysis, this should be the \"month\" column that will be used to define this period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_time = 'id'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define columns with predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring.db import get_optimal_numerical_type\n",
    "cols_pred = list(pd.read_csv(r'demo_data/TgtAnaPredList.CSV', sep = ',', decimal = '.', \n",
    "                   encoding = 'windows-1251', low_memory = False, header = None)[0])\n",
    "\n",
    "column_types = list(zip(data[cols_pred].columns,data[cols_pred].dtypes))\n",
    "cols_pred_cat = [col_name for col_name,dtype in column_types if dtype.name == 'category' or dtype.name == 'object']\n",
    "cols_pred_num = [col_name for col_name,dtype in column_types if ('float' in dtype.name) or ('int' in dtype.name)]\n",
    "\n",
    "# ALTERNATIVELY, DEFINE THE PREDICTOR NAMES MANUALLY\n",
    "\n",
    "# cols_pred_num = [\"Numerical_1\",\"Numerical_2\",\"Numerical_3\",\"Numerical_4\",\"Numerical_5\", ]\n",
    "# cols_pred_cat = [\"Categorical_1\", \"Categorical_2\",\"Categorical_3\",\"Categorical_4\",\"Categorical_5\"]\n",
    "\n",
    "for name, col in data.iteritems():\n",
    "    if name in cols_pred_num:\n",
    "        if not pd.api.types.is_numeric_dtype(col.values.dtype):\n",
    "            try:\n",
    "                col.astype(np.number)\n",
    "                data[name] = col.astype(get_optimal_numerical_type(col))\n",
    "            except:\n",
    "                print('Column {0} couldn\\'t be converted to numerical. Will be used as categorical.'.format(name))\n",
    "                cols_pred_num.remove(name)\n",
    "                cols_pred_cat.append(name)\n",
    "    \n",
    "    if name in cols_pred_cat:\n",
    "        if col.dtype.name not in {'object', 'string', 'category'}:\n",
    "            try:\n",
    "                data[name] = col.astype('category')\n",
    "            except:\n",
    "                data[name] = col.astype(str)\n",
    "\n",
    "print('List of numerical predictors: [{0}]\\n'.format(len(cols_pred_num)))\n",
    "for col in cols_pred_num:\n",
    "    print(str.ljust(col, 35), data[col].dtype.name)\n",
    "\n",
    "print('-'*100)\n",
    "print()\n",
    "print('List of categorical predictors: [{0}]\\n'.format(len(cols_pred_cat)))\n",
    "for col in cols_pred_cat:\n",
    "    print(str.ljust(col, 35), data[col].dtype.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Valid/Test split\n",
    "You can also add HOOT and OOT samples if you want to cut too old or too new data out from the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring.data_manipulation import data_sample_time_split\n",
    "\n",
    "data['data_type'] = data_sample_time_split(data, \n",
    "                           time_column = col_time,\n",
    "                           splitting_points = [],\n",
    "                           sample_sizes = [[ 0.4   , 0.3   , 0.3  ]],\n",
    "                           sample_names = [['train','valid','test']],\n",
    "                           #stratify_by_columns = [col_target],\n",
    "                           random_seed = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = (data['data_type'] == 'train')\n",
    "valid_mask = (data['data_type'] == 'valid')\n",
    "test_mask = (data['data_type'] == 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Targets to be analyzed\n",
    "Targets should be defined\n",
    " - either in a list of dictionaries as shown below. Each dictionary should consist of two entries: 'target' with target name and 'base' with corresponding base name.\n",
    " - or in a csv with two unnamed columns, first with target names and second with corresponding base names.\n",
    "\n",
    "**If bases do not exist in the data set, you will need to add them manually before proceeding!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINING TARGET AS DICTIONARY\n",
    "target_definitions = [\n",
    "    {'target':'y0', 'base':'b0'},\n",
    "    {'target':'y1', 'base':'b1'},\n",
    "    {'target':'y2', 'base':'b2'},\n",
    "    {'target':'y3', 'base':'b3'},\n",
    "    {'target':'y4', 'base':'b4'},\n",
    "]\n",
    "\n",
    "# LOADING DEFINITION FROM A FILE\n",
    "target_definitions = pd.read_csv(r'demo_data/TgtAnaTargetDef.CSV', sep = ',', decimal = '.', \n",
    "                   encoding = 'windows-1251', low_memory = False, header = None)\n",
    "target_definitions.columns = ['target','base']\n",
    "target_definitions = target_definitions.to_dict('records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target selection using XGBoost\n",
    "Helps to choose the best targets if from multiple candidates. Use fit() method:\n",
    " - for each target, it trains xgboost model (all categorical predictors are grouped and WOE-transformed before the boosting) using training and validation (for stopping) set\n",
    " - then Gini is measured for each such model using all possible targets and testing datasets\n",
    "\n",
    "So at the end, we have #targets x #targets Gini values in a matrix. Then the analyst can choose which target (for training) is the best (usually because the Gini of its model is high also for the other targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring.target_selection import XgbTargetSelection\n",
    "\n",
    "xgbsel = XgbTargetSelection(xgb_params=None, \n",
    "                            num_boost_round=500, \n",
    "                            early_stopping_rounds=25, \n",
    "                            group_count=5, \n",
    "                            min_samples_cat=200)\n",
    "ginisdf = xgbsel.fit(data_train = data[train_mask],\n",
    "                     data_valid = data[valid_mask],\n",
    "                     data_test = data[test_mask],\n",
    "                     target_definitions = target_definitions, \n",
    "                     cols_pred_num = cols_pred_num, \n",
    "                     cols_pred_cat = cols_pred_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ginisdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ginisdf.plot.bar()\n",
    "plt.legend(bbox_to_anchor=(1,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
